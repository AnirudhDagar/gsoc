{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Tutorial: TMVA PyTorch Interface\"\n",
    "> \"Get started with TMVA PyTorch Interface. Combine the power of PyTorch & ROOT!\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Anirudh Dagar\n",
    "- categories: [tmva, pytorch, root]\n",
    "- image: images/tmva.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This tutorial aims to walkthrough the latest addition in the [ROOT TMVA](https://github.com/root-project/root) module, **The PyTorch Interface!** This is specifically designed to utilize the puissance of [ROOT](http://root.cern.ch/) for working with high energy physics data, while leveraging the power and flexibility of the popular Machine Learning framework, PyTorch.\n",
    "\n",
    "The PyTorch interface allows HEP Scientists to be more ingenious with ideas and provides the ability to customize Machine Learning models to a far more preponderant extent than the Keras Interface.\n",
    "\n",
    "Here, we'll build a simple classifier in python using PyTorch and compare the performance to a few other methods on a test example root dataset. The same model can be achieved in C/C++ like other TMVA methods which are implemented in C/C++. You can follow [this](https://github.com/root-project/root/tree/master/tmva/pymva/test/testPyTorchClassification.C) if you prefer a C++ implementation.\n",
    "\n",
    "### Imports\n",
    "We start with importing the necessary modules required for the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n"
     ]
    }
   ],
   "source": [
    "from ROOT import TMVA, TFile, TTree, TCut\n",
    "from subprocess import call\n",
    "from os.path import isfile\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup TMVA\n",
    "\n",
    "TMVA requires initialization the PyMVA to utilize PyTorch. PyMVA is the interface for third-party MVA tools based on Python. It is created to make powerful external libraries easily accessible with a direct integration into the TMVA workflow. All PyMVA methods provide the same plug-and-play mechanisms as the TMVA methods. Because the base method of PyMVA is inherited from the TMVA base method, all options of internal TMVA methods apply for PyMVA methods as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA.Tools.Instance()\n",
    "TMVA.PyMethodBase.PyInitialize()\n",
    "\n",
    "output = TFile.Open('TMVA.root', 'RECREATE')\n",
    "factory = TMVA.Factory('TMVAClassification', output,\n",
    "                       '!V:!Silent:Color:DrawProgressBar:'\n",
    "                       'Transformations=D,G:AnalysisType=Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Below we start by downloading the dataset example dataset. The signal and background are loaded and read from the dataset. Finally we define our dataloader with options to help us control the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree TreeS of type Signal with 6000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree TreeB of type Background with 6000 events\n",
      "                         : Dataset[dataset] : Class index : 0  name : Signal\n",
      "                         : Dataset[dataset] : Class index : 1  name : Background\n"
     ]
    }
   ],
   "source": [
    "if not isfile('tmva_class_example.root'):\n",
    "    call(['curl', '-O', 'http://root.cern.ch/files/tmva_class_example.root'])\n",
    "\n",
    "data = TFile.Open('tmva_class_example.root')\n",
    "signal = data.Get('TreeS')\n",
    "background = data.Get('TreeB')\n",
    "\n",
    "dataloader = TMVA.DataLoader('dataset')\n",
    "for branch in signal.GetListOfBranches():\n",
    "    dataloader.AddVariable(branch.GetName())\n",
    "\n",
    "dataloader.AddSignalTree(signal, 1.0)\n",
    "dataloader.AddBackgroundTree(background, 1.0)\n",
    "dataloader.PrepareTrainingAndTestTree(TCut(''),\n",
    "                                      'nTrain_Signal=4000:'\n",
    "                                      'nTrain_Background=4000:'\n",
    "                                      'SplitMode=Random:'\n",
    "                                      'NormMode=NumEvents:!V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model\n",
    "\n",
    "Model Definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('linear_1', nn.Linear(in_features=4, out_features=64))\n",
    "model.add_module('relu', nn.ReLU())\n",
    "model.add_module('linear_2', nn.Linear(in_features=64, out_features=2))\n",
    "model.add_module('softmax', nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function and the Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train and predict function. Note that the arguments to train and predict function need to be fixed since we call the same method internally in the TMVA interface backend. A user may control the training process and the loop inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: You may implement the training loop using `tqdm` for a nice progress bar! ðŸ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs,\n",
    "          batch_size, optimizer, criterion, save_best, scheduler):\n",
    "    trainer = optimizer(model.parameters(), lr=0.01)\n",
    "    schedule, schedulerSteps = scheduler\n",
    "    best_val = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Loop\n",
    "        # Set to train mode\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            trainer.zero_grad()\n",
    "            output = model(X)\n",
    "            train_loss = criterion(output, y)\n",
    "            train_loss.backward()\n",
    "            trainer.step()\n",
    "\n",
    "            # print train statistics\n",
    "            running_train_loss += train_loss.item()\n",
    "            if i % 64 == 63:    # print every 64 mini-batches\n",
    "                print(f\"[Epoch {epoch+1}, {i+1}] train loss:\"\n",
    "                      f\"{running_train_loss / 64 :.3f}\")\n",
    "                running_train_loss = 0.0\n",
    "\n",
    "        if schedule:\n",
    "            schedule(optimizer, epoch, schedulerSteps)\n",
    "\n",
    "        # Validation Loop\n",
    "        # Set to eval mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (X, y) in enumerate(val_loader):\n",
    "                output = model(X)\n",
    "                val_loss = criterion(output, y)\n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "            curr_val = running_val_loss / len(val_loader)\n",
    "            if save_best:\n",
    "               if best_val==None:\n",
    "                   best_val = curr_val\n",
    "               best_val = save_best(model, curr_val, best_val)\n",
    "\n",
    "            # print val statistics per epoch\n",
    "            print(f\"[Epoch {epoch+1}] val loss: {curr_val :.3f}\")\n",
    "            running_val_loss = 0.0\n",
    "\n",
    "    print(f\"Finished Training on {epoch+1} Epochs!\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define predict function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: TMVA's interface deals with the dataset by converting them to numpy arrays internally and later serving torch dataloaders which we indeed pass into our training function. But, note that at test/inference time, we are presented with numpy array inputs and we need to convert those to PyTorch tensors within the `predict` method. Similarly, we need to return the predicted numpy array back to TMVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_X, batch_size=32):\n",
    "    # Set to eval mode\n",
    "    model.eval()\n",
    "   \n",
    "    X = torch.Tensor(test_X)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X)\n",
    "\n",
    "    return predictions.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the necessary components required for downloading, preprocessing, dataloaders,\n",
    "building our model, training loop, and a prediction method for evaluation. We need to share some of these components with the TMVA Interface backend.\n",
    "\n",
    "<br/>\n",
    "\n",
    "This can be simply done by defining dictionary: `load_model_custom_objects`\n",
    "\n",
    "**Keys:**\n",
    "* \"optimizer\"\n",
    "* \"criterion\"\n",
    "* \"train_func\"\n",
    "* \"predict_func\"\n",
    "\n",
    "<br/>\n",
    "\n",
    "> Note: The keys and the name of the dictionary need to be as specified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass optimizer, loss, train, predict function objects,\n",
    "# defined earlier, as values to the dictionary\n",
    "\n",
    "load_model_custom_objects = {\"optimizer\": optimizer, \"criterion\": loss,\n",
    "                             \"train_func\": train, \"predict_func\": predict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Store model\n",
    "\n",
    "Since the TMVA interface requires us to load the model from the stored file without re-definition of model class, we need to convert the model to torchscript before saving for achieving this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear_1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear_2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "m = torch.jit.script(model)\n",
    "torch.jit.save(m, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book TMVA methods\n",
    "\n",
    "Now we will proceed by booking the MVA methods which we require. We book Fisher and PyTorch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom objects for loading model :  {'optimizer': <class 'torch.optim.sgd.SGD'>, 'criterion': MSELoss(), 'train_func': <function train at 0x1307b99e0>, 'predict_func': <function predict at 0x1307b9f80>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodPyTorch object at 0x7f908f837600>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mFisher\u001b[0m\n",
      "                         : \n",
      "Fisher                   : [dataset] : Create Transformation \"D\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Fisher                   : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : Booking method: \u001b[1mPyTorch\u001b[0m\n",
      "                         : \n",
      "PyTorch                  : [dataset] : Create Transformation \"D\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "PyTorch                  : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Using PyTorch - setting special configuration options \n",
      "                         : Using PyTorch version 1\n",
      "                         :  Setup PyTorch Model \n",
      "                         : Loaded pytorch train function: \n",
      "                         : Loaded pytorch optimizer: \n",
      "                         : Loaded pytorch loss function: \n",
      "                         : Loaded pytorch predict function: \n",
      "                         : Load model from file: model.pt\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(dataloader, TMVA.Types.kFisher, 'Fisher',\n",
    "                   '!H:!V:Fisher:VarTransform=D,G')\n",
    "factory.BookMethod(dataloader, TMVA.Types.kPyTorch, 'PyTorch',\n",
    "                   'H:!V:VarTransform=D,G:FilenameModel=model.pt:'\n",
    "                   'NumEpochs=20:BatchSize=32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Call the `TrainAllMethods` from the factory object to initiate training.\n",
    "Note: The output of this cell has been hidden for better readability and to avoid the verbosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=Sequential\n",
      "  (linear_1): RecursiveScriptModule(original_name=Linear)\n",
      "  (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "  (linear_2): RecursiveScriptModule(original_name=Linear)\n",
      "  (softmax): RecursiveScriptModule(original_name=Softmax)\n",
      ")\n",
      "[Epoch 1, 64] train loss:0.224\n",
      "[Epoch 1, 128] train loss:0.197\n",
      "[Epoch 1, 192] train loss:0.179\n",
      "[Epoch 1] val loss: 0.172\n",
      "[Epoch 2, 64] train loss:0.168\n",
      "[Epoch 2, 128] train loss:0.164\n",
      "[Epoch 2, 192] train loss:0.155\n",
      "[Epoch 2] val loss: 0.154\n",
      "[Epoch 3, 64] train loss:0.151\n",
      "[Epoch 3, 128] train loss:0.152\n",
      "[Epoch 3, 192] train loss:0.144\n",
      "[Epoch 3] val loss: 0.145\n",
      "[Epoch 4, 64] train loss:0.142\n",
      "[Epoch 4, 128] train loss:0.146\n",
      "[Epoch 4, 192] train loss:0.137\n",
      "[Epoch 4] val loss: 0.140\n",
      "[Epoch 5, 64] train loss:0.136\n",
      "[Epoch 5, 128] train loss:0.142\n",
      "[Epoch 5, 192] train loss:0.132\n",
      "[Epoch 5] val loss: 0.136\n",
      "[Epoch 6, 64] train loss:0.132\n",
      "[Epoch 6, 128] train loss:0.138\n",
      "[Epoch 6, 192] train loss:0.129\n",
      "[Epoch 6] val loss: 0.133\n",
      "[Epoch 7, 64] train loss:0.129\n",
      "[Epoch 7, 128] train loss:0.136\n",
      "[Epoch 7, 192] train loss:0.126\n",
      "[Epoch 7] val loss: 0.131\n",
      "[Epoch 8, 64] train loss:0.127\n",
      "[Epoch 8, 128] train loss:0.134\n",
      "[Epoch 8, 192] train loss:0.123\n",
      "[Epoch 8] val loss: 0.129\n",
      "[Epoch 9, 64] train loss:0.124\n",
      "[Epoch 9, 128] train loss:0.132\n",
      "[Epoch 9, 192] train loss:0.121\n",
      "[Epoch 9] val loss: 0.127\n",
      "[Epoch 10, 64] train loss:0.122\n",
      "[Epoch 10, 128] train loss:0.130\n",
      "[Epoch 10, 192] train loss:0.119\n",
      "[Epoch 10] val loss: 0.125\n",
      "[Epoch 11, 64] train loss:0.121\n",
      "[Epoch 11, 128] train loss:0.128\n",
      "[Epoch 11, 192] train loss:0.117\n",
      "[Epoch 11] val loss: 0.124\n",
      "[Epoch 12, 64] train loss:0.119\n",
      "[Epoch 12, 128] train loss:0.127\n",
      "[Epoch 12, 192] train loss:0.116\n",
      "[Epoch 12] val loss: 0.122\n",
      "[Epoch 13, 64] train loss:0.117\n",
      "[Epoch 13, 128] train loss:0.125\n",
      "[Epoch 13, 192] train loss:0.114\n",
      "[Epoch 13] val loss: 0.121\n",
      "[Epoch 14, 64] train loss:0.116\n",
      "[Epoch 14, 128] train loss:0.124\n",
      "[Epoch 14, 192] train loss:0.113\n",
      "[Epoch 14] val loss: 0.120\n",
      "[Epoch 15, 64] train loss:0.114\n",
      "[Epoch 15, 128] train loss:0.123\n",
      "[Epoch 15, 192] train loss:0.112\n",
      "[Epoch 15] val loss: 0.119\n",
      "[Epoch 16, 64] train loss:0.113\n",
      "[Epoch 16, 128] train loss:0.122\n",
      "[Epoch 16, 192] train loss:0.111\n",
      "[Epoch 16] val loss: 0.118\n",
      "[Epoch 17, 64] train loss:0.112\n",
      "[Epoch 17, 128] train loss:0.121\n",
      "[Epoch 17, 192] train loss:0.109\n",
      "[Epoch 17] val loss: 0.117\n",
      "[Epoch 18, 64] train loss:0.111\n",
      "[Epoch 18, 128] train loss:0.120\n",
      "[Epoch 18, 192] train loss:0.108\n",
      "[Epoch 18] val loss: 0.116\n",
      "[Epoch 19, 64] train loss:0.110\n",
      "[Epoch 19, 128] train loss:0.119\n",
      "[Epoch 19, 192] train loss:0.108\n",
      "[Epoch 19] val loss: 0.115\n",
      "[Epoch 20, 64] train loss:0.109\n",
      "[Epoch 20, 128] train loss:0.118\n",
      "[Epoch 20, 192] train loss:0.107\n",
      "[Epoch 20] val loss: 0.114\n",
      "Finished Training on 20 Epochs!\n",
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree TreeS\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree TreeB\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 4000\n",
      "                         : Signal     -- testing events             : 2000\n",
      "                         : Signal     -- training and testing events: 6000\n",
      "                         : Background -- training events            : 4000\n",
      "                         : Background -- testing events             : 2000\n",
      "                         : Background -- training and testing events: 6000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------\n",
      "                         :             var1    var2    var3    var4\n",
      "                         :    var1:  +1.000  +0.391  +0.590  +0.813\n",
      "                         :    var2:  +0.391  +1.000  +0.692  +0.734\n",
      "                         :    var3:  +0.590  +0.692  +1.000  +0.851\n",
      "                         :    var4:  +0.813  +0.734  +0.851  +1.000\n",
      "                         : ----------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------\n",
      "                         :             var1    var2    var3    var4\n",
      "                         :    var1:  +1.000  +0.855  +0.914  +0.965\n",
      "                         :    var2:  +0.855  +1.000  +0.927  +0.936\n",
      "                         :    var3:  +0.914  +0.927  +1.000  +0.970\n",
      "                         :    var4:  +0.965  +0.936  +0.970  +1.000\n",
      "                         : ----------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : [dataset] : Create Transformation \"D\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Preparing the Decorrelation transformation...\n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  0.0084120     1.0019   [    -3.1195     5.7307 ]\n",
      "                         :     var2:  0.0078511    0.99981   [    -3.1195     5.7307 ]\n",
      "                         :     var3:  0.0083128     1.0011   [    -3.1195     5.7307 ]\n",
      "                         :     var4:  0.0076997    0.99886   [    -3.1195     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Train method: Fisher for Classification\n",
      "                         : \n",
      "                         : Preparing the Decorrelation transformation...\n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  0.0084120     1.0019   [    -3.1195     5.7307 ]\n",
      "                         :     var2:  0.0078511    0.99981   [    -3.1195     5.7307 ]\n",
      "                         :     var3:  0.0083128     1.0011   [    -3.1195     5.7307 ]\n",
      "                         :     var4:  0.0076997    0.99886   [    -3.1195     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Fisher                   : Results for Fisher coefficients:\n",
      "                         : NOTE: The coefficients must be applied to TRANFORMED variables\n",
      "                         :   List of the transformation: \n",
      "                         :   -- Deco\n",
      "                         :   -- Gauss\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :     var1:       -0.221\n",
      "                         :     var2:       -0.055\n",
      "                         :     var3:       +0.032\n",
      "                         :     var4:       +0.474\n",
      "                         : (offset):       -0.002\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 8000 events: 0.0486 sec         \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 0.0246 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PyTorch for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ PyTorch ] :\u001b[0m\n",
      "                         : \n",
      "                         : PyTorch is a scientific computing package supporting\n",
      "                         : automatic differentiation. This method wraps the training\n",
      "                         : and predictions steps of the PyTorch Python package for\n",
      "                         : TMVA, so that dataloading, preprocessing and evaluation\n",
      "                         : can be done within the TMVA system. To use this PyTorch\n",
      "                         : interface, you need to generatea model with PyTorch first.\n",
      "                         : Then, this model can be loaded and trained in TMVA.\n",
      "                         : \n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Preparing the Decorrelation transformation...\n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_PyTorch        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  0.0084120     1.0019   [    -3.1195     5.7307 ]\n",
      "                         :     var2:  0.0078511    0.99981   [    -3.1195     5.7307 ]\n",
      "                         :     var3:  0.0083128     1.0011   [    -3.1195     5.7307 ]\n",
      "                         :     var4:  0.0076997    0.99886   [    -3.1195     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_PyTorch        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  0.0084120     1.0019   [    -3.1195     5.7307 ]\n",
      "                         :     var2:  0.0078511    0.99981   [    -3.1195     5.7307 ]\n",
      "                         :     var3:  0.0083128     1.0011   [    -3.1195     5.7307 ]\n",
      "                         :     var4:  0.0076997    0.99886   [    -3.1195     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Split TMVA training data in 6400 training events and 1600 validation events\n",
      "                         : Print Training Model Architecture\n",
      "                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored\n",
      "                         : Elapsed time for training with 8000 events: 4.91 sec         \n",
      "PyTorch                  : [dataset] : Evaluation of PyTorch on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 0.0518 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_PyTorch.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_PyTorch.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "Fisher                   : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Discr. power\n",
      "                         : -------------------------------\n",
      "                         :    1 : var4      : 1.956e-01\n",
      "                         :    2 : var1      : 4.019e-02\n",
      "                         :    3 : var2      : 3.086e-03\n",
      "                         :    4 : var3      : 2.351e-04\n",
      "                         : -------------------------------\n",
      "                         : No variable ranking supplied by classifier: PyTorch\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_PyTorch.weights.xml\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Call the `TestAllMethods` from the factory object to initiate testing.\n",
    "Note: The output of this cell has been hidden for better readability and to avoid the verbosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom objects for loading model :  {'optimizer': <class 'torch.optim.sgd.SGD'>, 'criterion': MSELoss(), 'train_func': <function train at 0x1307b99e0>, 'predict_func': <function predict at 0x1307b9f80>}\n",
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: Fisher for Classification performance\n",
      "                         : \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.016 sec       \n",
      "Factory                  : Test method: PyTorch for Classification performance\n",
      "                         : \n",
      "                         :  Setup PyTorch Model \n",
      "                         : Loaded pytorch train function: \n",
      "                         : Loaded pytorch optimizer: \n",
      "                         : Loaded pytorch loss function: \n",
      "                         : Loaded pytorch predict function: \n",
      "                         : Load model from file: dataset/weights/TrainedModel_PyTorch.pt\n",
      "PyTorch                  : [dataset] : Evaluation of PyTorch on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.0258 sec       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Call the `EvaluateAllMethods` from the factory object to initiate evaluation. Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves, etc. using both training and tetsing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: Fisher\n",
      "                         : \n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.015907    0.98605   [    -2.8645     3.5534 ]\n",
      "                         :     var2:  0.0046941     1.0002   [    -3.2858     3.3764 ]\n",
      "                         :     var3:   0.017030    0.99729   [    -2.9032     5.7307 ]\n",
      "                         :     var4: -0.0011286    0.98455   [    -2.8276     3.2696 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Fisher                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.015907    0.98605   [    -2.8645     3.5534 ]\n",
      "                         :     var2:  0.0046941     1.0002   [    -3.2858     3.3764 ]\n",
      "                         :     var3:   0.017030    0.99729   [    -2.9032     5.7307 ]\n",
      "                         :     var4: -0.0011286    0.98455   [    -2.8276     3.2696 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: PyTorch\n",
      "                         : \n",
      "TFHandler_PyTorch        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.015907    0.98605   [    -2.8645     3.5534 ]\n",
      "                         :     var2:  0.0046941     1.0002   [    -3.2858     3.3764 ]\n",
      "                         :     var3:   0.017030    0.99729   [    -2.9032     5.7307 ]\n",
      "                         :     var4: -0.0011286    0.98455   [    -2.8276     3.2696 ]\n",
      "                         : -----------------------------------------------------------\n",
      "PyTorch                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_PyTorch        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.015907    0.98605   [    -2.8645     3.5534 ]\n",
      "                         :     var2:  0.0046941     1.0002   [    -3.2858     3.3764 ]\n",
      "                         :     var3:   0.017030    0.99729   [    -2.9032     5.7307 ]\n",
      "                         :     var4: -0.0011286    0.98455   [    -2.8276     3.2696 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       PyTorch        : 0.924\n",
      "                         : dataset       Fisher         : 0.880\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              PyTorch        : 0.317 (0.332)       0.757 (0.761)      0.946 (0.944)\n",
      "                         : dataset              Fisher         : 0.192 (0.190)       0.645 (0.646)      0.884 (0.876)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 4000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 8000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "We can now analyze the results using histogram plots and ROC curves. Several histograms are produced after calling evaluation, which can be examined with the TMVA GUI or directly using the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc = factory.GetROCCurve(dataloader)\n",
    "roc.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "With this I've wrapped up my project. Stay tuned for my final post about my GSoC journey at CERN.\n",
    "\n",
    "Feel free to ask questions below in the comments or on the [root forum](https://root-forum.cern.ch/).\n",
    "\n",
    "<br/>\n",
    "\n",
    "Until next time,\n",
    "\n",
    "Anirudh Dagar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7.7",
   "language": "python",
   "name": "python3.7.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
